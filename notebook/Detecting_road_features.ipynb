{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b8c2b72",
   "metadata": {},
   "source": [
    "# Detecting road features\n",
    "The goal of this project was to try and detect a set of road features in a forward facing vehicle camera data. This is a somewhat naive way as it is mainly using computer vision techniques (no relation to naive Bayesian!). Features we are going to detect and track are lane boundaries and surrounding vehicles.\n",
    "\n",
    "We are going to try detecting and tracking some basic road features in a video stream from a front-facing camera on a vehicle, this is clearly a very naive way of doing it and can hardly be applied in the field, however it is a good representation of what we can detect using mainly computer vision techniques: e.g. fiddling with color spaces and various filters. We will cover tracking of the following features:\n",
    "\n",
    "- **Lane boundaries**. Understanding where the lane is could be useful in many applications, be it a self-driving car or some driving assistant software.\n",
    "- **Surrounding vehicles**. Keeping track of other vehicles around you is just as important if you were to implement some collision-avoiding algorithm\n",
    "\n",
    "We will implement it in two major steps, first we will prepare a pipeline for lane tracking, and will then learn how to detect surrounding vehicles.\n",
    "\n",
    "## Source video\n",
    "\n",
    "I am going to use a short video clip shot from a vehicle front-facing camera while driving on a highway. It was shot in close to perfect conditions: sunny weather, not many vehicles around, road markings clearly visible, etc. — so using just computer vision techinques alone should be sufficient for a quick demonstration. You can check out the full [50 seconds video here.](https://github.com/qslia/detecting-road-features)\n",
    "![](images/project_source_video_sample.gif)\n",
    "\n",
    "## Lane Tracking\n",
    "\n",
    "Let’s first prepare a processing pipeline to identify the lane boundaries in a video. The pipeline includes the following steps that we apply to each frame:\n",
    "\n",
    "- **Camera calibration.** To cater for "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ff1b93",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24bb1da2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
